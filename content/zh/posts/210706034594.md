---
title: "kubertnetes1.18 kubeadm高可用安装"
date: 2021-07-06T10:34:59+08:00
description: 文章描述
draft: true
#true 为隐藏文章 false展示
#hideToc: false
#如 true 则会隐藏目录
#enableToc: true
#如 true 则会生成目录
#enableTocContent: true
#如 true 则会生成目录内容
#pinned: true  
#固定文章
#weight: 10000
#文章排序权重
keywords:
#关键词
- kubertnetes1.18 kubeadm高可用安装
author: CNSRE    
#作者
authorEmoji: ✍
tags:
- kubernetes
categories:
- kubernetes
#series:
#- 系列
image: https://cn-north-1-image.s3.cn-north-1.amazonaws.com.cn/cnsre/cnsre/20210603103755.png
#标题图片地址
# https://cn-north-1-image.s3.cn-north-1.amazonaws.com.cn/cnsre/cnsre/kubernetes.png
# kubernetes
---

---
> 作者：[SRE运维博客](https://www.cnsre.cn/)
> 博客地址：[https://www.cnsre.cn](https://www.cnsre.cn/)
> 文章地址：[https://www.cnsre.cn/posts/210706034594/](https://www.cnsre.cn/posts/210706034594/)
> 相关话题：[https://www.cnsre.cn/tags/kubernetes/](https://www.cnsre.cn/tags/kubernetes/)
---

## kubertnetes1.18 kubeadm高可用安装

### 1. 基础环境规划：

| 主机名  | IP地址     | 节点说明   |
| ------- | ---------- | ---------- |
| node1   | 10.0.0.61  | node节点   |
| node2   | 10.0.0.62  | node节点   |
| master1 | 10.0.0.63  | master节点 |
| master2 | 10.0.0.64  | master节点 |
| master3 | 10.0.0.65  | master节点 |
| 虚拟vip | 10.0.0.100 | 虚拟IP     |



### 2. v1.18更新说明

`kubectl debug是1.18新增的功能，可以设置一个临时容器`
`kubernetes1.18新增了内置的sidecar，它可以将业务应用日志输出到控制台的日志和打到本地文件，在pod中内置一个contanr 1.18可以让sidecar先启动，不会影响业务`
`持久化数据volume挂载到k8s中可能会修改权限，需要在启动容器之前需要修改权限，但是有的容器很大修改权限很慢，在新版本中volume不建议修改，系统可能会阻止，这种情况下可以在yaml定义`
`configmap一般放置明文配置文件，secret防止密文文件，如果热加载过程中更新到容器中会加载配置文件，配置文件错误导致起不来，所以在1.18后可以设置限制cecret不允许修改`



### 3.基础优化：

```
# 1. 关闭防火墙功能
systemctl stop firewalld
systemctl disable firewalld

# 2.关闭selinux
sed -i 's/enforcing/disabled/' /etc/selinux/config 
setenforce 0

# 3. 关闭swap
swapoff -a && sysctl -w vm.swappiness=0  # 临时
sed -ri 's/.*swap.*/#&/' /etc/fstab    # 永久


# 4. 服务器规划
cat << \EOF >/etc/hosts
127.0.0.1 localhost
10.0.0.61 master1
10.0.0.62 master2
10.0.0.63 master3
10.0.0.64 node1
10.0.0.65 node2
EOF


#5. 主机名配置:
# hostnamectl set-hostname [主机名]
# bash

#6. 时间同步配置
yum install -y ntpdate
echo '* * * * * tpdate time.windows.com' >>/var/spool/cron/root


#开启转发
echo  1 >/proc/sys/net/ipv4/ip_forward
sysctl -p

cat << \EOF >/etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sysctl --system
#没有添加该参数会导致pod无法被外部访问，这样会出现。 集群所有node都可以访问一个pod 唯独只有那么一两台不能访问，此时应该看这个配置是否打开


#7. 时间同步
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 
echo 'Asia/Shanghai' >/etc/localtime 
echo '*/5 * * * * /usr/sbin/ntpdate -u ntp.api.bz' >>/var/spool/cron/root
systemctl restart crond.service
crontab -l
# 以上可以全部复制粘贴直接运行,但是主机名配置需要重新修改



#8. 关闭dnsmasq[centos8]
systemctl disable --now dnsmasq

#9. limit配置：
echo '* soft nofile 655360' >>/etc/security/limits.conf

cat << \EOF >>/etc/security/limits.conf
* hard nofile 131072
* soft nproc 655350
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited
EOF

#10. 免密配置：
ssh-keygen -t rsa
for i in master1 master2 master3 node1 node2;do ssh-copy-id -i .ssh/id_rsa.pub $i;done


#11. 关闭NetworkManager
systemctl disable --now NetworkManager


#12. yum源：
cd /etc/yum.repos.d && rm -f *
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo
wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo
yum clean all
yum install -y bash-completion.noarch

#kubernetes源：
cat << \EOF >/etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF


#13. 内核升级：
#当前内核：
[root@master1 ~]# uname -r
3.10.0-693.el7.x86_64


rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm
#安装最新版：
yum --enablerepo=elrepo-kernel install kernel-ml kernel-ml-devel -y

grub2-set-default  0 && grub2-mkconfig -o /etc/grub2.cfg && grubby --args="user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)" && reboot

重启结束后查看内核：
[root@master1 ~]# uname -r
5.9.6-1.el7.elrepo.x86_64



#14. 安装ipvsadm：
yum install ipvsadm ipset sysstat conntrack libseccomp -y
#配置：

执行命令：
cat << \EOF >/etc/modules-load.d/ipvs.conf 
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack_ipv4
ip_tables
ip_set
xt_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
EOF

modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4

#启用
systemctl enable --now systemd-modules-load.service

#检查是否正确加载：
[root@master1 ~]#  lsmod | grep -e ip_vs -e nf_conntrack_ipv4
nf_conntrack_ipv4      15053  0 
nf_defrag_ipv4         12729  1 nf_conntrack_ipv4
ip_vs_sh               12688  0 
ip_vs_wrr              12697  0 
ip_vs_rr               12600  0 
ip_vs                 141092  6 ip_vs_rr,ip_vs_sh,ip_vs_wrr
nf_conntrack          133387  2 ip_vs,nf_conntrack_ipv4
libcrc32c              12644  3 xfs,ip_vs,nf_conntrack
```



### 基础组件安装：

```
#1. 安装docker：
#yum list docker-ce --showduplicates | sort -r       查看可用版本
yum -y install docker-ce-18.09.9-3.el7
   
#修改docker启动为systemd[建议修改]：   
----
rm -f /etc/docker/*
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://ajvcw8qn.mirror.aliyuncs.com"],
  "exec-opts": ["native.cgroupdriver=systemd"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker
systemctl enable docker.service   
systemctl status docker.service   
   
   
-----------------------------不建议修改--------------------------------
#修改docker驱动改为cgroupfs[不建议修改]：
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://ajvcw8qn.mirror.aliyuncs.com"],
  "exec-opts": ["native.cgroupdriver=cgroupfs"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker.service
systemctl enable --now docker.service
systemctl status docker.service
-----------------------------不建议修改--------------------------------




#2. 安装kubeadm：
yum list kubeadm.x86_64 --showduplicates | sort -r   #查看版本

#执行安装 kubeadm组件[默认会安装 kubectl kubeadm kubelet]
yum install kubeadm -y
systemctl daemon-reload
systemctl enable --now kubelet


#-----------------------------------------------
#3. 修改cgoup驱动：
cat << \EOF >/etc/sysconfig/kubelet
KUBELET_EXTRA_ARGS="--cgroup-driver=$DOCKER_CGROUPS --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1"
EOF

#检查驱动：
DOCKER_CGROUPS=$(docker info | grep 'Cgroup' | cut -d' ' -f4)
echo $DOCKER_CGROUPS

systemctl daemon-reload
systemctl enable --now kubelet
systemctl status kubelet
```



### master节点安装高可用组件：

```
yum install keepalived haproxy -y

mkdir /etc/haproxy
vim /etc/haproxy/haproxy.cfg 


#准备配置文件：
cat << \EOF >/etc/haproxy/haproxy.cfg
global
  maxconn  2000
  ulimit-n  16384
  log  127.0.0.1 local0 err
  stats timeout 30s

defaults
  log global
  mode  http
  option  httplog
  timeout connect 5000
  timeout client  50000
  timeout server  50000
  timeout http-request 15s
  timeout http-keep-alive 15s

frontend monitor-in
  bind *:33305
  mode http
  option httplog
  monitor-uri /monitor

frontend k8s-master
  bind 0.0.0.0:16443
  bind 127.0.0.1:16443
  mode tcp
  option tcplog
  tcp-request inspect-delay 5s
  default_backend k8s-master

backend k8s-master
  mode tcp
  option tcplog
  option tcp-check
  balance roundrobin
  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
  server k8s-master1    10.0.0.61:6443  check
  server k8s-master2    10.0.0.62:6443  check
  server k8s-master3    10.0.0.63:6443  check
EOF



## master1  master2 master3 同时执行：
#[mcast_src_ip 是master1的IP 在修改其他两个master节点的时候 这个ip应该改为当前master节点的ip]

#[master1 配置]
mkdir /etc/keepalived
cat << \EOF >/etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
    router_id LVS_DEVEL
}
vrrp_script chk_apiserver {
    script "/etc/keepalived/check_apiserver.sh"
    interval 2
    weight -5
    fall 3
    rise 2
}
vrrp_instance VI_1 {
    state MASTER
    interface ens160
    mcast_src_ip 10.0.0.61
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication {
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    }
    virtual_ipaddress {
        10.0.0.100
    }
#    track_script {
#       chk_apiserver
#    }
}
EOF




#--------------------------------------------------
#[master2 配置]：
mkdir /etc/keepalived
cat << \EOF >/etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
    router_id LVS_DEVEL
}
vrrp_script chk_apiserver {
    script "/etc/keepalived/check_apiserver.sh"
    interval 2
    weight -5
    fall 3
    rise 2
}
vrrp_instance VI_1 {
    state MASTER
    interface ens160
    mcast_src_ip 10.0.0.62
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication {
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    }
    virtual_ipaddress {
        10.0.0.100
    }
#    track_script {
#       chk_apiserver
#    }
}
EOF

#--------------------------------------------------

#[master3的配置]：
mkdir /etc/keepalived
cat << \EOF >/etc/keepalived/keepalived.conf
! Configuration File for keepalived
global_defs {
    router_id LVS_DEVEL
}
vrrp_script chk_apiserver {
    script "/etc/keepalived/check_apiserver.sh"
    interval 2
    weight -5
    fall 3
    rise 2
}
vrrp_instance VI_1 {
    state MASTER
    interface ens160
    mcast_src_ip 10.0.0.63
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication {
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    }
    virtual_ipaddress {
        10.0.0.100
    }
#    track_script {
#       chk_apiserver
#    }
}
EOF




## 检查检查部分 还没有配置脚本所以先这么写，后面添加检查脚本后 解除这块的注释
#    track_script {
#       chk_apiserver
#    }
```



### 健康检查脚本：

```
#每个master节点都加入这个健康检查脚本：

cat << \EOF >/etc/keepalived/check_apiserver.sh 
#!/bin/bash

err=0
for k in $(seq 1 5)
do
    check_code=$(pgrep kube-apiserver)
    if [[ $check_code == "" ]]; then
        err=$(expr $err + 1)
        sleep 5
        continue
    else
        err=0
        break
    fi
done

if [[ $err != "0" ]]; then
    echo "systemctl stop keepalived"
    /usr/bin/systemctl stop keepalived
    exit 1
else
    exit 0
fi
EOF


 
## 健康检查配置好了 需要把/etc/keepalived/keepalived.conf文件的健康检查部分打开
vim /etc/keepalived/keepalived.conf
```



### 启动keepalived与 haproxy

```
systemctl enable --now haproxy
systemctl enable --now keepalived


#检查应用端口：
[root@master1 ~]# netstat -lntup|grep 6443
tcp        0      0 127.0.0.1:16443         0.0.0.0:*               LISTEN      5312/haproxy
tcp        0      0 0.0.0.0:16443           0.0.0.0:*               LISTEN      5312/haproxy


#3台master安装telnet检测工具：
yum install -y telnet


#3台服务器启动keepalived haproxy
systemctl enable --now haproxy
systemctl enable --now keepalived
systemctl restart haproxy.service keepalived.service
systemctl status haproxy.service keepalived.service



#测试：
#ping 虚拟IP关闭多台keepalived后启动任意一台检查是否可以ping通：
[root@master1 ~]# ping 10.0.0.100
PING 10.0.0.100 (10.0.0.100) 56(84) bytes of data.
64 bytes from 10.0.0.100: icmp_seq=1 ttl=64 time=0.031 ms
64 bytes from 10.0.0.100: icmp_seq=2 ttl=64 time=0.031 ms

[root@k8s-master2 ~]# ping 10.0.0.100
PING 10.0.0.100 (10.0.0.100) 56(84) bytes of data.
64 bytes from 10.0.0.100: icmp_seq=12 ttl=64 time=1057 ms
64 bytes from 10.0.0.100: icmp_seq=13 ttl=64 time=33.4 ms

[root@k8s-master3 ~]# ping 10.0.0.100
PING 10.0.0.100 (10.0.0.100) 56(84) bytes of data.
64 bytes from 10.0.0.100: icmp_seq=1 ttl=64 time=0.581 ms
64 bytes from 10.0.0.100: icmp_seq=2 ttl=64 time=0.306 ms


telnet检测：
[root@k8s-master3 ~]# telnet 10.0.0.100 16443
Trying 10.0.0.100...
Connected to 10.0.0.100.
Escape character is '^]'.
Connection closed by foreign host.

如果不通或者在三秒内自动中断，则认为VIP不可以，不可在继续往下执行，需要排查keepalived的问题，比如防火墙和selinux，haproxy和keepalived的状态，监听端口等
所有节点查看防火墙状态必须为disable和inactive：systemctl status firewalld
所有节点查看selinux状态，必须为disable：getenforce
master节点查看haproxy和keepalived状态：systemctl status keepalived haproxy
master节点查看监听端口：netstat -lntp
```



### kubeadm配置：

```
# master01 配置文件

# cat kubeadm-config.yaml:
#-----------------------------------------------------------------
cat << \EOF >/root/kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: 7t2weq.bjbawausm0jaxury
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.0.61
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: k8s-master01
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  certSANs:
  - 10.0.0.100
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: 10.0.0.100:16443
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.18.5
networking:
  dnsDomain: cluster.local
  podSubnet: 172.168.0.0/16
  serviceSubnet: 10.96.0.0/12
scheduler: {}
EOF
#-----------------------------------------------------------------

#执行更新 kubeadm-config.yaml
kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml

版本报错处理办法：
检查当前版本：
[root@master1 ~]# kubelet --version
Kubernetes v1.19.3

修改/root/kubeadm-config.yaml 配置文件中的版本号为: 1.19.3
字段：
kubernetesVersion: v1.19.3


执行更改：
[root@master1 ~]# kubeadm reset 
[root@master1 ~]# systemctl start kubelet
[root@master1 ~]# kubeadm init --config /root/kubeadm-config.yaml  --upload-certs


----------------------------------------------------------------------------------------------------------------

# master02 配置文件

# cat kubeadm-config.yaml:
#-----------------------------------------------------------------
cat << \EOF >/root/kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: 7t2weq.bjbawausm0jaxury
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.0.62
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: k8s-master01
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  certSANs:
  - 10.0.0.100
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: 10.0.0.100:16443
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.18.5
networking:
  dnsDomain: cluster.local
  podSubnet: 172.168.0.0/16
  serviceSubnet: 10.96.0.0/12
scheduler: {}
EOF
#-----------------------------------------------------------------

#执行更新 kubeadm-config.yaml
kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml






-------------------------------------------------------------------------------------------------------
# master03 配置文件

# cat kubeadm-config.yaml:
#-----------------------------------------------------------------
cat << \EOF >kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: 7t2weq.bjbawausm0jaxury
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.0.63
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: k8s-master01
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  certSANs:
  - 10.0.0.100
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: 10.0.0.100:16443
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.18.5
networking:
  dnsDomain: cluster.local
  podSubnet: 172.168.0.0/16
  serviceSubnet: 10.96.0.0/12
scheduler: {}
EOF
#-----------------------------------------------------------------

#执行更新配置 kubeadm-config.yaml
kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml




##  [master] 所有Master节点提前下载镜像，可以节省初始化时间
kubeadm config images pull --config /root/kubeadm-config.yaml


## 所有节点设置开机自启动kubelet
systemctl enable --now kubelet
```



### master 节点初始化：

```
Master01节点初始化:

```


---
> 作者：[SRE运维博客](https://www.cnsre.cn/)
> 博客地址：[https://www.cnsre.cn](https://www.cnsre.cn/)
> 文章地址：[https://www.cnsre.cn/posts/210706034594/](https://www.cnsre.cn/posts/210706034594/)
> 相关话题：[https://www.cnsre.cn/tags/kubernetes/](https://www.cnsre.cn/tags/kubernetes/)
---

